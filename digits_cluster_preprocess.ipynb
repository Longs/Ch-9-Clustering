{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_digits, y_digits = load_digits(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits,y_digits)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to scale the data for Logistic Regression otherwise it won't converge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  4., 15.,  6.,  0.,  0.,  0.,  0.,  0., 13., 13.,\n",
       "        1.,  0.,  0.,  0.,  0.,  7., 16.,  2.,  0.,  0.,  0.,  0.,  4.,\n",
       "       15.,  8.,  0.,  5.,  0.,  0.,  0., 11., 14.,  1.,  6., 16.,  5.,\n",
       "        0.,  1., 16., 14., 12., 16., 16.,  3.,  0.,  0., 10., 12., 10.,\n",
       "       16., 10.,  0.,  0.,  0.,  0.,  0.,  6., 16.,  2.,  0.,  0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.35530978, -1.10813628, -1.94267032,  0.73889945,\n",
       "        0.05167137, -0.40183839, -0.12249676, -0.05760195, -0.63272168,\n",
       "       -1.99555289,  0.24819837,  0.58240087, -1.1856311 , -0.51261039,\n",
       "       -0.12400944, -0.04453802, -0.72663898, -0.50824588,  1.58623486,\n",
       "       -0.80979601, -1.25070269, -0.55316874, -0.11208582, -0.03856149,\n",
       "        0.49317659,  0.97114649, -0.13808323, -1.60435961, -0.4223247 ,\n",
       "       -0.61872863, -0.02725696,  0.        ,  2.49504273,  0.99680246,\n",
       "       -1.29805404, -0.72501235,  1.22258731,  0.59568028,  0.        ,\n",
       "        6.3393133 ,  4.95947298,  1.0612487 ,  0.75270657,  1.35415583,\n",
       "        1.3494101 , -0.12205756, -0.09334883, -0.03856149,  5.41465192,\n",
       "        0.78434186,  0.09095421,  1.27619782,  0.18794902, -0.76646078,\n",
       "       -0.21377744,  0.        , -0.32263582, -1.09982558, -1.47623864,\n",
       "        0.8502854 , -0.81233275, -0.50734698, -0.19260118])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg=LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "log_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg=LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_train_scaled,y_train)\n",
    "\n",
    "log_reg.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try using KMeans for feature engineering\n",
    "* Cluster the data\n",
    "* Represent each instance by the distance from the centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 99 candidates, totalling 297 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cluster', KMeans()),\n",
       "                                       ('log_reg',\n",
       "                                        LogisticRegression(max_iter=5000,\n",
       "                                                           multi_class='ovr',\n",
       "                                                           random_state=42))]),\n",
       "             n_jobs=6, param_grid={'cluster__n_clusters': range(2, 200, 2)},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pl_kmeans = Pipeline([\n",
    "    (\"cluster\",KMeans()), \n",
    "    (\"log_reg\",LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "    )])\n",
    "\n",
    "param_grid = dict(cluster__n_clusters=range(2,200,2))\n",
    "\n",
    "grid_km_clf = GridSearchCV(pl_kmeans,param_grid,cv=3,verbose=2,n_jobs=6)\n",
    "\n",
    "grid_km_clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9836674090571641\n",
      "{'cluster__n_clusters': 162}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9622222222222222"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Above outputs cleared because LogisticRegression constantly fails because of lack of scaling\n",
    "\n",
    "print(grid_km_clf.best_score_)\n",
    "print(grid_km_clf.best_params_)\n",
    "grid_km_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction in error rate from adding Kmeans (no subsequent scaling) 15.00%\n"
     ]
    }
   ],
   "source": [
    "error_reduction = -((1-grid_km_clf.score(X_test,y_test)-(1-log_reg.score(X_test_scaled,y_test)))/(1-log_reg.score(X_test_scaled,y_test)))\n",
    "print (f\"Reduction in error rate from adding Kmeans (no subsequent scaling) {error_reduction:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 99 candidates, totalling 297 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cluster', KMeans(n_init=40)),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('log_reg',\n",
       "                                        LogisticRegression(max_iter=5000,\n",
       "                                                           multi_class='ovr',\n",
       "                                                           random_state=42))]),\n",
       "             n_jobs=6, param_grid={'cluster__n_clusters': range(2, 200, 2)},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now try scaling the output from KMeans\n",
    "pl_kmeans_scaled = Pipeline([\n",
    "    (\"cluster\",KMeans(n_init=40)), \n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"log_reg\",LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42))\n",
    "    ])\n",
    "\n",
    "param_grid = dict(cluster__n_clusters=range(2,200,2))\n",
    "\n",
    "grid_km_scaled_clf = GridSearchCV(pl_kmeans_scaled,param_grid,cv=3,verbose=2,n_jobs=6)\n",
    "#Not using scaled data as will be scaling after the kmeans step\n",
    "grid_km_scaled_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9821826280623608\n",
      "{'cluster__n_clusters': 152}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9622222222222222"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid_km_scaled_clf.best_score_)\n",
    "print(grid_km_scaled_clf.best_params_)\n",
    "grid_km_scaled_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scaling speeds convergence of Logistic Regression\n",
    "* no evidence of non-convergence from unscaled - just takes roughly 4 times longer\n",
    "* Using these extra cycles to enhance quality of the clustering algorithm (by increasing the number of initial centroids used):\n",
    "    * little benefit observed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kmeans clustering pre-processing does not improve\n",
    "* raw RFC gets 96.89% \n",
    "* k means gets 96.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw RFC performance 96.89%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_RFC = RandomForestClassifier(random_state=42,n_estimators=1000)\n",
    "\n",
    "clf_RFC.fit(X_train,y_train)\n",
    "print(f\"Raw RFC performance {clf_RFC.score(X_test,y_test):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Kmeans RFC performance 96.22%\n"
     ]
    }
   ],
   "source": [
    "rfc_score=[]\n",
    "for clusters in range(2,200,2):\n",
    "    KM = KMeans(n_clusters=clusters).fit(X_train,y_train)\n",
    "    X_Kmeans = KM.transform(X_train) #X_means is now cluster distances\n",
    "    rfc = RandomForestClassifier(random_state=42,n_estimators=1000)\n",
    "    rfc.fit(X_Kmeans,y_train)\n",
    "    x_test_Kmeans = KM.transform(X_test)\n",
    "    rfc_score.append(rfc.score(x_test_Kmeans,y_test))\n",
    "\n",
    "print(f\"Max Kmeans RFC performance {max(rfc_score):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Kmeans RFC performance 96.67%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(range(2,200,2),rfc_score)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Max Kmeans RFC performance {max(rfc_score):.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('PandasNumpyMathplotlib')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40a6d3daba109dd36035c486cbe134237beb3103005e5f3b9c526cde33e5461d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
